{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b0892e",
   "metadata": {},
   "source": [
    "# Module 5: Software Testing Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb79db",
   "metadata": {},
   "source": [
    "This module focuses on using prompts for complete testing workflows: analyzing requirements, designing test cases (functional, E2E, exploratory), creating test data, and writing bug reports. You will use various prompting techniques to cover different testing aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf4e07",
   "metadata": {},
   "source": [
    "\n",
    "USE: lab_order_processing.py\n",
    "\n",
    "### Task 1: Analyze requirements and find ambiguities\n",
    "#### Prompt: \"Analyze the requirements in lab_order_processing.py user story and identify ambiguities, missing details, and assumptions\"\n",
    "\n",
    "What happens: Copilot reviews requirements and lists unclear points like what happens at exactly $50, order minimum validation timing, cancellation process details\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19644e",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "Quick extraction — explicit requirements (from lab_order_processing.py)\n",
    "User story: \"As a customer, I want to place and track orders so that I can receive my purchased items.\"\n",
    "Requirements listed in the file:\n",
    "Customers can place orders with multiple items\n",
    "Order total must be greater than $10\n",
    "Free shipping for orders above $50\n",
    "Orders can be cancelled within 24 hours\n",
    "Order status values: pending, confirmed, shipped, delivered, cancelled\n",
    "Ambiguities and missing details (what a developer would need clarified)\n",
    "Item structure and validation\n",
    "What does each item look like? (sku/id, unit_price, quantity, description, weight, dimensions)\n",
    "Should we validate that total_amount equals sum(unit_price * quantity) for all items?\n",
    "Currency, rounding, and taxes\n",
    "Currency is implied ($) but not explicit — multi-currency support or locale formatting not specified.\n",
    "No guidance on tax calculations (sales tax/VAT): are totals tax-inclusive or tax applied at checkout?\n",
    "Rounding rules (e.g., cents, bankers rounding) are not specified.\n",
    "Order total vs. minimum and free shipping thresholds\n",
    "Are thresholds applied to subtotal, subtotal after discounts, or total after tax and shipping?\n",
    "Does the $10 minimum apply before or after discounts?\n",
    "Discounts and promotions\n",
    "Discount application order is unspecified (discounts before/after shipping/taxes).\n",
    "Stacking rules (can multiple codes be used?), expiration, validation of codes, and limits are missing.\n",
    "Shipping calculation details\n",
    "Only a single flat value is coded (5.99). No shipping methods (overnight, standard), address-based zones, weight-based costs, or carrier integration.\n",
    "No expected delivery time windows or tracking number handling.\n",
    "Inventory and fulfillment\n",
    "No inventory checks or reservation/locking logic mentioned; what happens if stock is insufficient?\n",
    "Partial shipments behavior (ship items separately) is not covered.\n",
    "Payment processing\n",
    "The user story implies \"place orders\" but payment flow (authorize/charge, payment providers, retries, failed payments) is not described.\n",
    "Idempotency of \"create order\" on retries is not specified.\n",
    "Cancellation semantics\n",
    "\"Cancelled within 24 hours\": which timestamp is used? (order created time, localized timezone?)\n",
    "Consequences of cancellation: refund flow, restock, reversing shipments, notifications.\n",
    "What if order is already shipped within 24 hours?\n",
    "Status transitions and constraints\n",
    "Allowed transitions between statuses not defined (e.g., can you move from delivered back to cancelled?).\n",
    "Who can change statuses (system only, admin, customer for cancellation)?\n",
    "API/return contract and error handling\n",
    "Current functions mix strings and dicts as return values; no consistent error model (exceptions vs errors in responses).\n",
    "No HTTP contract/response codes or service-level errors specified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef05201",
   "metadata": {},
   "source": [
    "### Task 2: Generate functional test cases\n",
    "#### Prompt: \"Generate functional test cases for create_order function covering valid orders, minimum amount validation, empty items check, and edge cases\"\n",
    "\n",
    "What happens: Copilot creates test cases testing core functionality with different input combinations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137be097",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "I'll (1) update the todo list, (2) add a unittest file module_5/test_lab_order_processing.py with functional tests for create_order, and (3) run the tests to verify — expected outcome: tests created and executed, with results shown. I'll now perform these steps.\n",
    "\n",
    "I'll run the test file directly with Python's unittest runner so we get executable test output (why: the test-run tool didn't discover tests). Expected outcome: console output with test results.\n",
    "\n",
    "Run \n",
    "python -m unittest \"c:\\Users\\admin\\OneDrive - Blue Data Consulting\\Prompt Engineering\\module_5\\test_lab_order_processing.py\"\n",
    "\n",
    "Done — I added functional tests and updated the todo list.\n",
    "\n",
    "What I changed\n",
    "\n",
    "Created test file: test_lab_order_processing.py\n",
    "Contains unittest tests for create_order covering:\n",
    "valid order (happy path)\n",
    "minimum amount validation (< $10)\n",
    "empty items list and None items\n",
    "exact minimum ($10)\n",
    "negative total\n",
    "invalid total type (string) raising TypeError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a6319b",
   "metadata": {},
   "source": [
    "### Task 3: Create end-to-end test scenario\n",
    "#### Prompt: \"Create end-to-end test scenario for complete order flow: create order, calculate shipping, apply discount, update status to delivered\"\n",
    "\n",
    "What happens: Copilot generates sequential test covering entire order lifecycle from creation to delivery\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c6080",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "I'll (1) add an end-to-end unittest file for the full order flow and (2) run the new tests to show results — expected outcome: a new test file and test run output. I'll update the todo list to track progress before making changes.\n",
    "\n",
    "Progress update — what I ran and next steps\n",
    "\n",
    "I added an end-to-end unittest file: test_e2e_order_flow.py and updated the todo list.\n",
    "I attempted to run the tests here but the run step was skipped; I haven't captured live test output.\n",
    "What the new E2E test does\n",
    "\n",
    "Creates a multi-item order with subtotal $60 using create_order.\n",
    "Applies discount code \"SAVE10\" (expects 10% off → $54).\n",
    "Calls calculate_shipping on the discounted amount (expects free shipping).\n",
    "Updates order status through confirmed, shipped, and delivered, asserting the update messages.\n",
    "How to run the new end-to-end test (PowerShell)\n",
    "\n",
    "From your workspace root run:\n",
    "For verbose output:\n",
    "Expected results (given current lab_order_processing.py)\n",
    "\n",
    "The test should pass end-to-end because:\n",
    "create_order returns a dict with status \"pending\".\n",
    "apply_discount_code(\"SAVE10\") returns total * 0.9.\n",
    "calculate_shipping returns 0 for amounts >= 50.\n",
    "update_order_status accepts the statuses and returns \"Status updated to <status>\".\n",
    "Next steps — pick one\n",
    "\n",
    "I can retry running the test here (I'll run the unittest runner and paste results).\n",
    "If tests fail locally, paste the output and I’ll fix either the tests or the implementation and re-run (up to 3 iterations).\n",
    "I can extend the E2E test to verify return types and final stored order state (if we refactor to store orders rather than returning static dicts)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97746b22",
   "metadata": {},
   "source": [
    "### Task 4: Generate exploratory test charter\n",
    "#### Prompt: \"Generate exploratory test charter for order processing system covering areas to explore, test ideas, and risks to investigate\"\n",
    "\n",
    "What happens: Copilot creates structured charter with exploration areas, time box, and what to look for\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f4d3b",
   "metadata": {},
   "source": [
    "Answer:- \n",
    "\n",
    "Exploratory Test Charter — Order Processing System\n",
    "Goal / Mission\n",
    "\n",
    "Rapidly explore the order processing flow to discover bugs, usability issues, and business-rule gaps that would affect customers placing, paying for, shipping, and cancelling orders.\n",
    "Focus on real-world scenarios, edge cases, and integration points (discounts, shipping, inventory, payments).\n",
    "Timebox\n",
    "\n",
    "90-minute session (adjustable). Break into three 30-minute segments: happy-path + smoke, boundary/edge cases, integrations & error handling.\n",
    "Scope (what to test)\n",
    "\n",
    "Order creation: single and multi-item orders, totals vs. item sums, currency/rounding behavior.\n",
    "Discounts and promotions: single/multiple codes, expired/invalid, stacking, case-sensitivity.\n",
    "Shipping calculation: thresholds (exact $50), address/zone effects, weight/quantity impact (if available).\n",
    "Payment flow: authorization vs capture, declined cards, retries, idempotency on retry.\n",
    "Cancellation and refunds: within 24 hours, exactly at 24-hour boundary, post-shipment behavior, refund timing.\n",
    "Order status and transitions: allowed transitions, invalid transitions, role-based permissions.\n",
    "Inventory and fulfillment: stock reservation, oversell race conditions, partial shipments/backorders.\n",
    "Error handling & messages: validation errors, business-rule errors, consistent response structure.\n",
    "Security & permissions: order viewing/updating by different users, injection or malformed inputs.\n",
    "Performance/scale smoke: placing many small orders quickly, concurrent cancellations/updates.\n",
    "Usability & UX cues (if UI exists): clear messages, helpful validation, visibility of order id and tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a5941",
   "metadata": {},
   "source": [
    "### Task 5: Create equivalence partition test data\n",
    "#### Prompt: \"Create test data for calculate_shipping using equivalence partitioning: amounts below $50, exactly $50, above $50\"\n",
    "\n",
    "What happens: Copilot generates test data sets representing each partition with sample values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ec2b7",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "I'll create a small unittest file with equivalence-partition test cases for calculate_shipping (why: produce reusable test artifacts and runnable checks; outcome: file added and tests executed). I'll then run the test file to show results.\n",
    "\n",
    "test_calculate_shipping_eqp.py\n",
    "\n",
    "python -m unittest \"c:\\Users\\admin\\OneDrive - Blue Data Consulting\\Prompt Engineering\\module_5\\test_calculate_shipping_eqp.py\" -v\n",
    "\n",
    "What I added\n",
    "\n",
    "New test file: test_calculate_shipping_eqp.py\n",
    "Tests using equivalence partitioning:\n",
    "Below $50: sample values 0.0, 1.0, 49.99 → expect shipping 5.99\n",
    "Exactly $50: 50.0 → expect shipping 0\n",
    "Above $50: 50.01, 51.0, 100.0 → expect shipping 0\n",
    "Negative amount: -10.0 → current implementation treats as below threshold, expects 5.99\n",
    "How to run the tests (PowerShell)\n",
    "\n",
    "Run the new test directly:\n",
    "python -m unittest \"c:\\Users\\admin\\OneDrive - Blue Data Consulting\\Prompt Engineering\\module_5\\test_calculate_shipping_eqp.py\" -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e7c628",
   "metadata": {},
   "source": [
    "### Task 6: Generate boundary value test cases\n",
    "#### Prompt: \"Generate boundary value test cases for create_order minimum amount: $9.99, $10, $10.01\"\n",
    "\n",
    "What happens: Copilot creates tests at boundaries of minimum order amount validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb061c",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "Progress update — boundary tests added\n",
    "\n",
    "What I changed\n",
    "\n",
    "Added test_create_order_boundary.py with three boundary test cases:\n",
    "$9.99 — expected rejection with message \"Order minimum is $10\"\n",
    "$10.00 — expected acceptance and status \"pending\"\n",
    "$10.01 — expected acceptance and status \"pending\"\n",
    "Why these tests\n",
    "\n",
    "They target the minimum-order validation boundary and will catch off-by-one or floating-point comparison issues.\n",
    "How to run the tests (PowerShell)\n",
    "\n",
    "Run the new test file directly:\n",
    "python -m unittest \"c:\\Users\\admin\\OneDrive - Blue Data Consulting\\Prompt Engineering\\module_5\\test_create_order_boundary.py\" -v\n",
    "\n",
    "Expected results with current lab_order_processing.py\n",
    "\n",
    "9.99 -> returned string \"Order minimum is $10\" (test asserts that)\n",
    "10.00 and 10.01 -> returned dict with status \"pending\" (tests assert that)\n",
    "Next steps\n",
    "\n",
    "I can run the tests here and paste the output (if you want me to execute them now).\n",
    "I can also:\n",
    "Add more boundary tests (e.g., 9.999, very large values, type errors).\n",
    "Convert tests to use Decimal for more precise monetary assertions and modify the implementation accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b79cb",
   "metadata": {},
   "source": [
    "### Task 7: Create persona-based test data\n",
    "#### Prompt: \"Create persona-based test data for order processing: budget shopper, premium customer, bulk buyer with their typical order patterns\"\n",
    "\n",
    "What happens: Copilot generates realistic test data based on different customer personas and behaviors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534b490",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "I'll add a todo item for persona test data, create a JSON fixture module_5/persona_test_data.json with three personas and example orders, then mark the todo done — outcome: a reusable test-data file you can load in tests. I'll now add the todo and the file.\n",
    "\n",
    "Added 1 todo\n",
    "\n",
    "persona_test_data.json\n",
    "Fixing an invalid JSON expression in the added file (compute subtotal for the bulk mixed order), then mark the persona-data todo completed; outcome: valid JSON fixture and updated todo state. I'll apply the fix and update the todo list.\n",
    "\n",
    "persona_test_data.json+1-1\n",
    "Completed (7/7) Create persona-based test data\n",
    "\n",
    "Progress update — persona test data created and validated\n",
    "\n",
    "I added a JSON fixture: persona_test_data.json containing three personas (budget_shopper, premium_customer, bulk_buyer) with example orders, expected behaviors, and usage notes.\n",
    "I corrected an earlier JSON error (computed subtotal expression) and finalized the file.\n",
    "The todo item for persona data is now marked completed.\n",
    "Where the file is\n",
    "\n",
    "persona_test_data.json\n",
    "What’s inside (summary)\n",
    "\n",
    "budget_shopper\n",
    "\n",
    "Cases: below_minimum (subtotal 4.99), near_boundary (9.99), small_with_discount (12.00 with SAVE10 -> expects 10.80)\n",
    "Tags: smoke, boundary, discount\n",
    "Purpose: test minimum validation, discount application, and UI/validation messaging.\n",
    "premium_customer\n",
    "\n",
    "Cases: single_high_value (120.00 with SAVE20 -> expects 96.00), multiple_premium_items (subtotal 290.00)\n",
    "Tags: happy-path, performance, payment\n",
    "Purpose: test high-value flows, free shipping, payment capture, lifecycle progression.\n",
    "bulk_buyer\n",
    "\n",
    "Cases: large_quantity_single_sku (1000 units of small item, subtotal 500.00), mixed_large_order_with_backorder (subtotal 2250.00)\n",
    "Tags: stress, inventory, partial-shipment\n",
    "Purpose: test inventory reservation, partial shipments/backorders, and performance under large payloads.\n",
    "Notes\n",
    "\n",
    "Usage guidance: load this JSON in unit/integration tests and iterate over persona example_orders to create parameterized tests.\n",
    "Recommendation: use Decimal for monetary calculations in tests to avoid floating-point issues; add currency field if multi-currency needed.\n",
    "How to use the data in tests (example)\n",
    "\n",
    "Load JSON and iterate orders to feed into your existing test functions (pseudocode):\n",
    "\n",
    "import json\n",
    "from decimal import Decimal\n",
    "\n",
    "with open('module_5/persona_test_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for persona in data['personas']:\n",
    "    for order_case in persona['example_orders']:\n",
    "        subtotal = Decimal(str(order_case['subtotal']))\n",
    "        items = order_case['items']\n",
    "        # call create_order(customer_id, items, subtotal) etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebf9adc",
   "metadata": {},
   "source": [
    "### Task 8: Generate non-functional test scenarios\n",
    "#### Prompt: \"Generate non-functional test scenarios for lab_order_processing.py covering performance, security, and usability\"\n",
    "\n",
    "What happens: Copilot creates tests for response time, data security, and user experience aspects\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f9cd8f",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "I'll add a todo entry marking non-functional scenarios as in-progress, then produce the scenarios; afterward I'll mark the todo completed and summarize next steps. Expected outcome: new todo created and scenarios delivered.\n",
    "\n",
    "Added 1 todo\n",
    "\n",
    "Progress update: added todo \"Create non-functional test scenarios\" (in-progress). Below are the performance, security, and usability test scenarios for lab_order_processing.py. Each scenario includes objective, environment/test data, steps, metrics/acceptance criteria, and tool suggestions (with optional commands for running basic checks).\n",
    "\n",
    "Non-functional test scenarios for lab_order_processing.py\n",
    "General test data and environment\n",
    "\n",
    "Use a staging environment that mirrors production (same DB size/schema, same auth, same network conditions, but safe test payment endpoints).\n",
    "Use the persona fixture persona_test_data.json and boundary/functional tests created earlier (re-use budget_shopper, premium_customer, bulk_buyer cases).\n",
    "Use realistic dataset sizes: thousands of customers, tens of thousands of orders in DB to mimic dataset effects.\n",
    "Prefer reproducible runs: seed DB, reset state between runs, and use dedicated test accounts for payments.\n",
    "A. Performance scenarios\n",
    "Load / Throughput test\n",
    "Objective: Validate system can process X orders per second (e.g., 50 RPS sustained) for order creation and status updates without errors.\n",
    "Environment: Staging; DB with representative dataset; HTTP load generator.\n",
    "Test data: Mix of persona orders (30% budget, 50% premium, 20% bulk).\n",
    "Steps:\n",
    "Start with a warmup period (2 minutes) at 10 RPS.\n",
    "Ramp to target throughput over 5 minutes, sustain for 15 minutes.\n",
    "Exercise endpoints: POST /create_order, POST /apply_discount, GET /calculate_shipping, POST /update_order_status.\n",
    "Metrics / Acceptance:\n",
    "p95 latency ≤ 500ms for create_order, p99 ≤ 1.5s.\n",
    "Error rate < 1% (failures or HTTP 5xx).\n",
    "CPU < 80% and memory stable on app nodes.\n",
    "Tools: k6, Locust, JMeter.\n",
    "Example (k6, PowerShell):\n",
    "\n",
    "##### run a local k6 script (example.js) that hits create_order endpoint\n",
    "k6 run --vus 50 --duration 15m c:\\path\\to\\order_load_test.js\n",
    "\n",
    "2. Spike and Stress test\n",
    "\n",
    "Objective: Observe graceful degradation and recovery under sudden spikes or beyond capacity.\n",
    "Steps:\n",
    "Ramp to 10x normal traffic within 30s, hold 1 min, then drop to 0.\n",
    "Increase until the system fails; record threshold.\n",
    "Acceptance:\n",
    "System recovers to normal throughput within 5 minutes of spike end.\n",
    "No data loss (orders queued or retried logically).\n",
    "Tools: k6/locust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7ccb6",
   "metadata": {},
   "source": [
    "### Task 9: Write detailed bug report\n",
    "#### Prompt: \"Write detailed bug report for cancel_order function: it accepts exactly 24 hours but requirement says within 24 hours. Include severity, impact, steps to reproduce, expected vs actual\"\n",
    "\n",
    "What happens: Copilot generates comprehensive bug report with all standard fields and clear description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d073e3d5",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "I'll write the bug report now (includes reproduction steps, impact, severity, suggested fix, and a unit test you can add to catch it).\n",
    "\n",
    "Bug report — cancel_order accepts exactly 24 hours (boundary mismatch)\n",
    "Title\n",
    "\n",
    "cancel_order allows cancellation at exactly 24 hours since order creation; requirement states \"within 24 hours\"\n",
    "ID\n",
    "\n",
    "BR-0001 (suggested)\n",
    "Reported\n",
    "\n",
    "November 11, 2025\n",
    "Affected file / function\n",
    "\n",
    "lab_order_processing.py — function cancel_order(order_id, hours_since_order)\n",
    "Summary\n",
    "\n",
    "The requirement says \"Orders can be cancelled within 24 hours\". The implementation uses the condition if hours_since_order > 24: return \"Cannot cancel after 24 hours\" which permits cancellation when hours_since_order == 24. This contradicts \"within 24 hours\" (commonly interpreted as strictly less than 24 hours), allowing cancellations at the 24-hour boundary when they should be disallowed.\n",
    "Severity\n",
    "\n",
    "Medium (Business rule / policy violation)\n",
    "Rationale: This is a domain/business rule enforcement bug (cancellation policy). It can impact revenue, refund policy enforcement and customer expectations. Not a crash, but incorrect behavior with potential financial/legal implications.\n",
    "Priority\n",
    "\n",
    "P2 / High-Medium — fix should be scheduled soon (before release or policy-affected flows go live).\n",
    "Environment / Scope\n",
    "\n",
    "Present in the Python implementation in lab_order_processing.py.\n",
    "Likely affects any consumer of cancel_order (API layer, UI) that relies on this function for enforcing cancellation window.\n",
    "Also relevant for any automated reconciliation or refund processes that assume this rule.\n",
    "Steps to reproduce (minimal)\n",
    "\n",
    "Open Python REPL or a small script in the project root where lab_order_processing.py is importable.\n",
    "Import the function and call it with hours_since_order = 24:\n",
    "Python reproduction example:\n",
    "\n",
    "from module_5.lab_order_processing import cancel_order\n",
    "\n",
    "order_id = \"ORD_TEST\"\n",
    "hours_since_order = 24  # exactly 24 hours\n",
    "\n",
    "print(cancel_order(order_id, hours_since_order))\n",
    "#### Actual output (current): \"Order cancelled\"\n",
    "\n",
    "Observe returned value \"Order cancelled\" — which violates \"within 24 hours\".\n",
    "Expected result\n",
    "\n",
    "Cancellation should be allowed only when the elapsed time is strictly less than 24 hours.\n",
    "For hours_since_order == 24, the function should return rejection: e.g., \"Cannot cancel after 24 hours\" (or clearer: \"Cancellation window expired — cannot cancel after 24 hours\").\n",
    "Actual result\n",
    "\n",
    "Function returns \"Order cancelled\" for hours_since_order == 24.\n",
    "Business/Functional impact\n",
    "\n",
    "Customers could cancel at the exact 24-hour mark even if policy forbids it, causing:\n",
    "Incorrect refunds or charge reversals.\n",
    "Breaks in operational or legal policy enforcement.\n",
    "Potential abuse if exact timing is exploited.\n",
    "Confusion if UI says \"within 24 hours\" but allows cancellation at 24:00:00.\n",
    "Likelihood / Frequency\n",
    "\n",
    "Low-to-medium in normal operations (depends on precision of time tracking). But boundary cases occur and are likely in timezone/precision-sensitive systems and automated scheduling.\n",
    "Root cause (analysis)\n",
    "\n",
    "Off-by-one/inequality boundary: code uses > rather than >=, interpreting \"within\" as \"<= 24\" (inclusive) rather than strictly less than 24 hours.\n",
    "Also: function accepts hours_since_order float or integer; time measurement precision (hours as float) and timezone/datetime semantics are not considered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c390cfa",
   "metadata": {},
   "source": [
    "### Task 10: Create bug advocacy statement\n",
    "#### Prompt: \"Create bug advocacy statement explaining why the discount code case sensitivity issue in apply_discount_code is critical and should be fixed immediately\"\n",
    "\n",
    "What happens: Copilot writes persuasive explanation of bug impact on business and customers with supporting arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084eab40",
   "metadata": {},
   "source": [
    "Answer:-\n",
    "\n",
    "Preamble: I'm going to document a persuasive bug advocacy statement explaining why the discount-code case-sensitivity bug in apply_discount_code is critical and needs an immediate fix — outcome: clear business impact, technical risk, reproduction, and recommended urgencies.\n",
    "\n",
    "Bug Advocacy Statement — Discount Code Case Sensitivity (apply_discount_code)\n",
    "\n",
    "Summary / Title\n",
    "\n",
    "Discount code acceptance is case-sensitive in apply_discount_code (e.g., \"SAVE10\" works but \"save10\" or \"Save10\" do not). This causes valid-looking codes entered by customers to be rejected.\n",
    "Why this matters (business impact)\n",
    "\n",
    "Revenue & Conversion: Customers who expect a promo to work but are rejected will abandon checkout — directly reducing conversion rates and revenue.\n",
    "Customer trust & churn: Inconsistent promo behavior frustrates customers and harms brand trust; complaints escalate to support and social channels.\n",
    "Marketing & Ops failure: Marketing campaigns using codes (often communicated in varied casing across channels or user-generated content) will underperform, skewing campaign analytics and ROI.\n",
    "Support costs & disputes: Increased support tickets, refund requests, and manual code validations add operational overhead and potential chargebacks.\n",
    "Legal/advertising compliance: If campaign terms advertised a promo (without specifying case sensitivity), blocking users on case alone may be considered poor practice and could create disputes.\n",
    "Technical severity & scope\n",
    "\n",
    "Severity: High (P1/P2 depending on campaign cadence). It's a functional correctness issue affecting a critical monetization flow.\n",
    "Scope: apply_discount_code currently only checks exact matches (\"SAVE10\", \"SAVE20\"). Any variation in user input casing will be rejected even if the code is valid.\n",
    "Reproducibility: Deterministic and easily reproducible with simple inputs.\n",
    "Reproduction steps (quick)\n",
    "\n",
    "Call apply_discount_code(total_amount=100.0, discount_code=\"SAVE10\") -> returns 90.0 (10% off).\n",
    "Call apply_discount_code(total_amount=100.0, discount_code=\"save10\") -> returns 100.0 (no discount).\n",
    "Similarly \"Save10\" or \"SAVE10 \" (trailing space) are likely rejected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt_env (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
